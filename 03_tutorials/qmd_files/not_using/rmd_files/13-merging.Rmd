# Combining and joining

Often, as data journalists, we're looking at data across time or at data stored in multiple tables. And to do that, we need to often need to merge that data together.

Depending on what we have, we may just need to stack data on top of each other to make new data. If we have 2019 data and 2018 data and we want that to be one file, we stack them. If we have a dataset of cows in counties and a dataset of populations in county, we're going to join those two together on the county -- the common element.  

Let's explore.

## Combining data (stacking)

Let's say that we have county population estimates for three different years - [2010](https://umd.box.com/s/vsuyt7v1gtb2u0aerliv5eixfmzfgt17), [2015](https://umd.box.com/s/2qijnwfygsrfin9d2o1krhzw5o8vza30) and [2020](https://umd.box.com/s/uqkeaabkvs4ge0l10j3w3sa76q3z1v16) - in three different files. They have the same record layout and the same number of counties. We can combine them into a single dataframe.

Let's do what we need to import them properly. I've merged it all into one step for each of the three datasets.

```{r}
library(tidyverse)
```

```{r}
popestimate_2010 <- read_csv("data/popestimate_2010.csv")
```

```{r}
popestimate_2015 <- read_csv("data/popestimate_2015.csv")
```

```{r}
popestimate_2020 <- read_csv("data/popestimate_2020.csv")
```

All three of these datasets have the same number of columns, all with the same names, so if we want to merge them together to compare them over time, we need to stack them together. The verb here, in R, is `bind_rows`. You tell the function what you want to combine and it does it, assuming that you've got column names in common containing identically formatted data.

Since we have three dataframes, we're going to need to pass them as a list, meaning they'll be enclosed inside the `list` function.

```{r}
estimates <- bind_rows(list(popestimate_2010, popestimate_2015, popestimate_2020))
```

And boom, like that, we have 9,852 rows of data together instead of three dataframes. There are plenty of uses for `bind_rows`: any regularly updated data that comes in the same format like crime reports or award recipients or player game statistics.

## Joining data

More difficult is when you have two separate tables that are connected by a common element or elements.

Let's start by reading in the Maryland PPP loan applications data:

```{r}
maryland_ppp <- read_csv('data/ppp_applications_md.csv')
```

One of the columns we have is called `naics_code`, which is a six-digit number used by the federal government "in classifying business establishments for the purpose of collecting, analyzing, and publishing statistical data related to the U.S. business economy." More details at [the official NAICS site](https://www.census.gov/naics/).

But unless you have a particular interest in memorizing what those more than 1,000 codes actually mean, the codes themselves don't help you understand what type of business any individual applicant has. Luckily, we can merge that information into our data using a join.

Using a [CSV file of the 2017 NAICS codes](https://umd.box.com/s/thou3merdzwzbdimbvd06zkax1zndcsk), let's read the file into R:

```{r}
naics_codes <- read_csv('data/naics_codes.csv')
```

To put the Maryland applications and NAICS codes together, we need to use something called a join. There are different kinds of joins. It's better if you think of two tables sitting next to each other. A `left_join` takes all the records from the left table and only the records that match in the right one. A `right_join` does the same thing. An `inner_join` takes only the records where they are equal. There's one other join -- a `full_join` which returns all rows of both, regardless of if there's a match -- but I've never once had a use for a full join.

In the best-case scenario, the two tables we want to join share a common column. In this case, both of our tables have a column called `naics_code` that has the same characteristics: both are six-digit numbers.

We can do this join multiple ways and get a similar result. We can put the Maryland file on the left and the NAICS codes on the right and use a left join to get them all together. And we use `by=` to join by the correct column. And to avoid rendering hundreds of rows of data, I'm going to count the rows at the end. The reason I'm going this is important: **Rule 1 in joining data is having an idea of what you are expecting to get**. So with a left join with applications on the left, I have 195,869 applications, so I expect to get 195,869 rows when I'm done.

```{r}
maryland_ppp %>% left_join(naics_codes, by="naics_code") %>% select(name, naics_code, title) %>% nrow()
```

Remove the nrow and run it again for yourself. By default, `dplyr` will do a "natural" join, where it'll match all the matching columns in both tables. So if we take out the by, it'll use all the common columns between the tables. That may not be right in every instance but let's try it. If it works, we should get 195,869 rows.

```{r}
maryland_ppp %>% left_join(naics_codes) %>% select(name, naics_code, title)
```

Since we only have one column in common between the two tables, the join only used that column. And we got the same answer. If we had more columns in common, you could see in your results columns with .X after them - that's a sign of duplicative columns between two tables, and you may decide you don't need both moving forward.

Let's save our joined data to a new dataframe, but this time let's remove the select function so we don't limit the columns to just three.

```{r}
maryland_ppp_with_naics <- maryland_ppp %>% left_join(naics_codes)
```

Now, with our joined data, we can answer questions in a more useful way. But joins can do even more than just provide lookups; they can bring in additional data to enable you to ask more sophisticated questions.

Let's try adding zip code demographic data to the mix. Using [a file from the state's data catalog](https://umd.box.com/s/2xsq2rpkmg4ct3a77vt8j5bu4vu1z0tf), we can read it into R:

```{r}
maryland_zcta <- read_csv('data/maryland_zcta.csv')
```

You'll want to keep open the [data documentation](https://geodata.md.gov/imap/rest/services/Demographics/MD_CensusData/FeatureServer/1) that hosts the data, because the field names are abbreviations.

Note that this file describes Zip Code Tabulation Areas, which are very similar to but not always identical to zip codes (there's a [good explanation from the Census Bureau](https://www.census.gov/programs-surveys/geography/guidance/geo-areas/zctas.html)). Bottom line: "In most instances the ZCTA code is the same as the ZIP Code for an area."

Again, we can use a `left_join` to make our demographic data available. This time we'll need to specify the two fields to join because they do not have identical names. We'll use `zip` from our PPP data and `ZCTA5N` from the demographic data:

```{r, error=TRUE}
maryland_ppp_with_naics_and_demographics <- maryland_ppp_with_naics %>% left_join(maryland_zcta, by=c("zip"="ZCTA5N"))
```

You probably got an error when running that:


Error: Can't join on `x$zip` x `y$zip` because of incompatible types.
ℹ `x$zip` is of type <character>>.
ℹ `y$zip` is of type <double>>

Let's unpack this: R is saying it can't join those two columns because one of them is a character column and the other is a double (number) column. When joining, _the two columns need to have the same data type_.

We can fix that using our pal `mutate`. Let's change the ZCTA data to be a character, since zip codes aren't really useful as numbers (nobody needs to know the average zip code value).

```{r}
maryland_zcta <- maryland_zcta %>% mutate(across(ZCTA5N, as.character))
```

Now we can re-run the join:

```{r}
maryland_ppp_with_naics_and_demographics <- maryland_ppp_with_naics %>% left_join(maryland_zcta, by=c("zip"="ZCTA5N"))

maryland_ppp_with_naics_and_demographics
```

Now, if you use the tiny black right arrows to see what's in those demographic columns, you'll see ... a lot of NAs. What's going on there? Are there zip codes in the PPP data that aren't in the ZCTA data? If you go back using the left arrows, you can see that the PPP zip codes often are zip+4, and we're using the ZCTA5N field to join, which is a 5-character field. But not all of the PPP codes are zip+4. So we'll need to use `mutate` once more to give us a PPP zip field that is exactly 5 characters. Let's do this on the original `maryland` dataframe so we can then do the join using our new `zip5` field:

```{r}
maryland_ppp_with_naics <- maryland_ppp_with_naics %>% mutate(zip5 = str_sub(zip, 1, 5))
maryland_ppp_with_naics_and_demographics <- maryland_ppp_with_naics %>% left_join(maryland_zcta, by=c("zip5"="ZCTA5N"))
```

Now we've got PPP data and demographic data by zip code. That means we can draw from both datasets in asking our questions. For example, we could see the mean and median loan amount in zip codes with different demographic characteristics. Let's start with zip codes that have more than 50 percent non-Hispanic Black population.

We get this by using filter followed by summarize. In this case, we want PNHB > 50:

```{r}
maryland_ppp_with_naics_and_demographics %>%
  filter(PNHB > 50) %>%
  summarize(
    count = n(),
    avgamount = mean(amount),
    medamount = median(amount))
```

According to our query, there were 44,032 loans approved in zip codes with more than 50 percent non-Hispanic Black population, and the average amount was $53,836 and the median amount was $20,000.

Let's change that to zip codes with more than 50 percent non-Hispanic white population:

```{r}
maryland_ppp_with_naics_and_demographics %>%
  filter(PNHW > 50) %>%
  summarize(
    count = n(),
    avgamount = mean(amount),
    medamount = median(amount))
```

And we get a greater number of loans with a higher average and median amount. But that's not the end of the story, or of our questions. We'll need to ask more.

Let's break this down one more step. What if we added `rural_urban_indicator` -- if the loan recipient is located in a rural or urban area -- as a group_by. Does that change anything for the previous queries?

```{r}
maryland_ppp_with_naics_and_demographics %>%
  filter(PNHB > 50) %>%
  group_by(rural_urban_indicator) %>%
  summarize(
    count = n(),
    avgamount = mean(amount),
    medamount = median(amount))
```

```{r}
maryland_ppp_with_naics_and_demographics %>%
  filter(PNHW > 50) %>%
  group_by(rural_urban_indicator) %>%
  summarize(
    count = n(),
    avgamount = mean(amount),
    medamount = median(amount))
```

In both cases, urban applicants got more approvals for higher average and median amounts, and the gap between majority-white zip codes and majority-Black zip codes was larger for urban applicants than for rural ones.

Joining datasets allows you to expand the range and sophistication of questions you're able to ask. It is one of the most powerful tools in a journalist's toolkit.
